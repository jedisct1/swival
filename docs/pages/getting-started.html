<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Getting Started — Swival</title>
    <meta name="description" content="Getting Started — Swival documentation">
    <meta property="og:type" content="article">
    <meta property="og:title" content="Getting Started — Swival">
    <meta property="og:description" content="Getting Started — Swival documentation">
    <meta property="og:image" content="https://swival.dev/img/logo.png">
    <meta property="og:url" content="https://swival.dev/pages/getting-started.html">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Getting Started — Swival">
    <meta name="twitter:description" content="Getting Started — Swival documentation">
    <meta name="twitter:image" content="https://swival.dev/img/logo.png">
    <link rel="icon" href="../favicon.ico">
    <link rel="stylesheet" href="../css/style.css">
</head>
<body>
    <header class="site-header">
        <div class="header-inner">
            <a href="../" class="header-logo">
                <img src="../img/logo.png" alt="Swival">
            </a>
            <nav class="header-nav">
                <a href="./">Docs</a>
                <a href="https://github.com/swival/swival">GitHub</a>
            </nav>
        </div>
    </header>
    <div class="docs-layout">
        <aside class="sidebar">
            <div class="sidebar-section">
<h4>Basics</h4>
<ul>
<li><a href="getting-started.html" class="active">Getting Started</a></li>
<li><a href="usage.html">Usage</a></li>
<li><a href="tools.html">Tools</a></li>
</ul>
</div>
<div class="sidebar-section">
<h4>Configuration & Deployment</h4>
<ul>
<li><a href="safety-and-sandboxing.html">Safety & Sandboxing</a></li>
<li><a href="skills.html">Skills</a></li>
<li><a href="mcp.html">MCP</a></li>
<li><a href="customization.html">Customization</a></li>
<li><a href="providers.html">Providers</a></li>
<li><a href="reports.html">Reports</a></li>
<li><a href="reviews.html">Reviews</a></li>
<li><a href="agentfs.html">AgentFS</a></li>
</ul>
</div>
        </aside>
        <article class="docs-content">
            <h1 id="getting-started">Getting Started</h1>
<h2 id="prerequisites">Prerequisites</h2>
<p>Swival requires Python 3.13 or newer and <a href="https://docs.astral.sh/uv/">uv</a>. If <code>uv</code> is not installed yet, you can install it with the command below.</p>
<pre><code class="language-sh">curl -LsSf https://astral.sh/uv/install.sh | sh
</code></pre>
<h2 id="installation">Installation</h2>
<p>Install the CLI with <code>uv tool install swival</code>. This places the <code>swival</code> command on your <code>PATH</code>, so you can run it from any directory.</p>
<pre><code class="language-sh">uv tool install swival
</code></pre>
<h2 id="upgrading">Upgrading</h2>
<p>To upgrade an existing installation to the newest release, run <code>uv tool upgrade swival</code>.</p>
<pre><code class="language-sh">uv tool upgrade swival
</code></pre>
<p>If you ever want to remove it, run <code>uv tool uninstall swival</code>.</p>
<pre><code class="language-sh">uv tool uninstall swival
</code></pre>
<h2 id="running-with-lm-studio">Running with LM Studio</h2>
<p>LM Studio is the default provider and usually the fastest way to get started. Install LM Studio from <a href="https://lmstudio.ai/">lmstudio.ai</a>, load a tool-calling model, and start the local server from the Local Server tab. If your machine can handle it, increase the context window, because larger context gives the agent more room to reason over your codebase.</p>
<p>Once LM Studio is running, this is enough to start:</p>
<pre><code class="language-sh">swival &quot;Hello world&quot;
</code></pre>
<p>By default, Swival connects to <code>http://127.0.0.1:1234</code>, queries LM Studio for the currently loaded model, and uses that model automatically.</p>
<h2 id="what-happens-internally">What Happens Internally</h2>
<p>When you run a task against LM Studio, Swival first calls <code>/api/v1/models</code> to discover the loaded model and context size. It then builds a system prompt that includes tool definitions and workspace context, sends your task through LiteLLM, and enters the agent loop where the model can read files, edit files, search, and continue tool-calling until it finishes. When the model returns a final text answer with no more tool calls, Swival prints that answer to standard output and exits.</p>
<p>Diagnostic logs such as turn headers, tool traces, and timing information are written to standard error, which keeps standard output clean for piping into other tools.</p>
<h2 id="running-with-huggingface">Running with HuggingFace</h2>
<p>If you prefer hosted inference over running models locally, you can use the HuggingFace Inference API. Create a token at <a href="https://huggingface.co/settings/tokens">huggingface.co/settings/tokens</a> if you don't have one already, then export it so Swival can authenticate.</p>
<pre><code class="language-sh">export HF_TOKEN=hf_your_token_here
</code></pre>
<p>Pick a model that supports tool calling and pass it in <code>org/model</code> format.</p>
<pre><code class="language-sh">swival &quot;Hello world&quot; --provider huggingface --model zai-org/GLM-5
</code></pre>
<p>This uses HuggingFace's serverless inference, which is the fastest way to try hosted models without provisioning anything. Serverless endpoints often have smaller context windows than local deployments, so long multi-turn sessions can hit context pressure sooner.</p>
<p>If you need more headroom, you can provision a dedicated HuggingFace endpoint and pass its URL directly. Dedicated endpoints let you use the full deployed context window.</p>
<pre><code class="language-sh">swival &quot;Hello world&quot; \
    --provider huggingface \
    --model zai-org/GLM-5 \
    --base-url https://xyz.endpoints.huggingface.cloud \
    --api-key hf_your_key
</code></pre>
<p>For a deeper look at HuggingFace-specific options, see <a href="providers.html">Providers</a>.</p>
<h2 id="running-with-openrouter">Running with OpenRouter</h2>
<p>OpenRouter gives you access to models from many providers through a single API key. Sign up at <a href="https://openrouter.ai/">openrouter.ai</a> and grab your API key from the dashboard.</p>
<pre><code class="language-sh">export OPENROUTER_API_KEY=sk_or_your_token_here
</code></pre>
<p>Then pass the model you want to use. OpenRouter has both free and paid tiers.</p>
<pre><code class="language-sh">swival &quot;Hello world&quot; --provider openrouter --model z-ai/glm-5
</code></pre>
<p>OpenRouter models vary widely in context limits, so you should set <code>--max-context-tokens</code> to match the model you chose. Without it, Swival falls back to a conservative default that may not use the full window your model supports.</p>
<pre><code class="language-sh">swival &quot;Hello world&quot; \
    --provider openrouter \
    --model z-ai/glm-5 \
    --max-context-tokens 131072
</code></pre>
<p>For a deeper look at OpenRouter-specific options, see <a href="providers.html">Providers</a>.</p>
<h2 id="running-with-any-openai-compatible-server">Running with Any OpenAI-Compatible Server</h2>
<p>If you're running ollama, llama.cpp, mlx_lm.server, vLLM, or any other server that exposes an OpenAI-compatible API, use the generic provider.</p>
<pre><code class="language-sh">swival &quot;Hello world&quot; \
    --provider generic \
    --base-url http://127.0.0.1:8080 \
    --model my-model
</code></pre>
<p>Both <code>--model</code> and <code>--base-url</code> are required. No API key is needed for most local servers. If your server requires one, pass <code>--api-key</code> or set <code>OPENAI_API_KEY</code>.</p>
<p>For a deeper look at generic provider options and server-specific examples, see <a href="providers.html">Providers</a>.</p>
<h2 id="where-to-go-next">Where To Go Next</h2>
<p>If you want the full command surface and mode behavior, continue with <a href="usage.html">Usage</a>. If you want a deeper look at built-in capabilities, read <a href="tools.html">Tools</a>. If you need to understand trust boundaries before enabling stronger actions, read <a href="safety-and-sandboxing.html">Safety and Sandboxing</a>.</p>
<p>If you want to connect external tool servers via MCP, see <a href="mcp.html">MCP</a>. If you want copy-on-write isolation so you can review and apply changes only when ready, read <a href="agentfs.html">Using Swival with AgentFS</a>.</p>
        </article>
    </div>
    <footer class="site-footer">
        MIT License &middot;
        <a href="https://github.com/swival/swival">GitHub</a>
    </footer>
</body>
</html>